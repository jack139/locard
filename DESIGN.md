## 开放场景的身份证件定位方法

### 问题提出

这里所说的“身份证件”是指具有头像照片和文字描述的卡片式证件，例如：二代身份证、社保卡、医保卡、工牌等。

在传统需要对身份证件进行扫描识别的场景，通常使用平板扫描或高拍仪等设备进行图像采集，以确保对扫描或拍照的光照、背景、文字方向等进行有效控制，从而有助于后续对身份证件上的文字和图片进行识别。我们将此类场景定义为“特定场景”的图像采集。在当前移动互联网时代，许多需要进行图像采集的场景，例如使用各类手机App或微信公众号时，通常需要使用手机或平板设备的拍照功能进行采集，因而对清晰度、环境光、背景、手持遮挡、摆放方向、倾斜角度等条件不能进行统一的控制。此类对外部条件不可控的图片采集场景，我们定义为“开放场景”。

目前业务系统中最常见的“开放场景”应用是：用户通过手机对身份证件进行拍照上传，系统对上传的证件照片识别出身份信息，为用户自动填写相关的个人身份信息，例如姓名、出生年月、身份证号等，从而免去了用户手工输入的麻烦。而在此类开放场景中拍摄的证件照片，通常因为上述不可控的因素，导致不能有效对身份证件进行定位、检测和识别。

因此，本方案提出了一个应用于开发场景的身份证件定位方法，通过使用深度神经网络，对输入的图片进行计算和处理，定位身份证件在原始图片中的位置和方向，经过调整后进一步定位到身份证件上的头像照片和文字信息的位置。这些位置信息是后续对文字和头像照片进行识别的重要前提条件。


### 方法概述

主要步骤：
1. 将原始图片转换为模型输入张量
2. 使用证件定位模型进行计算，获得证件和头像照片的位置信息
3. 从原始图片截取证件图片，转换为模型输入张量
4. 使用CTPN网络模型进行文本检测，获得文字序列的位置信息

过程示例图片如下：

|                    原始图片                     |                  定位证件和头像照片                  |                     定位文本                     |
| :---------------------------------------------: | :----------------------------------------------: | :----------------------------------------------: |
| <img src="examples/1.jpg" style="zoom: 20%;" /> | <img src="examples/1a.jpg" style="zoom: 20%;" /> | <img src="examples/1b.jpg" style="zoom: 20%;" /> |
| <img src="examples/2.jpg" style="zoom: 20%;" /> | <img src="examples/2a.jpg" style="zoom: 20%;" /> | <img src="examples/2b.jpg" style="zoom: 20%;" /> |
| <img src="examples/3.jpg" style="zoom: 20%;" /> | <img src="examples/3a.jpg" style="zoom: 20%;" /> | <img src="examples/3b.jpg" style="zoom: 20%;" /> |


### 定位证件和头像的方法

模型基础基于VGG16神经网络模型

### 定位文本的方法

基于CTPN网络模型
